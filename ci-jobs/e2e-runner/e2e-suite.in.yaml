apiVersion: batch/v1
kind: Job
metadata:
  name: e2e-suite
  labels:
    jobgroup: ansible-runner
spec:
  backoffLimit: 0
  template:
    metadata:
      name: e2e-suite
      labels:
        jobgroup: ansible-runner
    spec:
      backoffLimit: 0
      terminationGracePeriodSeconds: 900
      containers:
      - name: lease
        image: registry.svc.ci.openshift.org/ci/boskoscli:latest
        terminationMessagePolicy: FallbackToLogsOnError
        resources:
          requests:
            cpu: 10m
            memory: 10Mi
          limits:
            memory: 200Mi
        volumeMounts:
        - name: shared-tmp
          mountPath: /tmp/shared
        - name: cluster-profile
          mountPath: /etc/openshift-installer
        - name: installer-artifacts
          mountPath: /tmp/artifacts
        env:
        - name: LEASE_OWNER
          value: ovirt-manual-run
        - name: LEASE_TYPE
          value: PLACEHOLDER_LEASE_TYPE
        command:
        - /bin/bash
        - -c
        - |
          #!/bin/bash
          set -euo pipefail

          trap 'rc=$?; CHILDREN=$(jobs -p); if test -n "${CHILDREN}"; then kill ${CHILDREN} && wait; fi; if test "${rc}" -ne 0; then touch /tmp/shared/exit; fi; exit "${rc}"' EXIT

          # hack for bazel
          function boskosctl() {
            /app/boskos/cmd/cli/app.binary "${@}"
          }

          function extract_leases_info() {
            echo "$( jq ."${1}" --raw-output "${2}" )"
          }

          lease_type="ovirt-quota-slice"

          echo "[INFO] Acquiring a lease ..."
          resource="$( boskosctl --server-url http://boskos.ci --owner-name "${LEASE_OWNER}" acquire --type "${lease_type}" --state "free" --target-state "leased" --timeout 150m )"
          resource_name="$(echo "${resource}"|jq .name --raw-output)"
          lease_path="/etc/openshift-installer/${resource_name}.json"
          echo "[INFO] Lease acquired! at $(date --utc) Leased resource: ${resource}"
          echo "[INFO] Sending heartbeats to retain the lease ${resource_name}"
          boskosctl --server-url http://boskos.ci --owner-name "${LEASE_OWNER}" heartbeat --resource "${resource}" &
          heartbeats_pid=$!

          #For conformance runs we require double resources
          if [ "${LEASE_TYPE}" == "conformance" ]; then
            resource_conformance="$( boskosctl --server-url http://boskos.ci --owner-name "${LEASE_OWNER}" acquire --type "${lease_type}" --state "free" --target-state "leased" --timeout 150m )"
            resource_conformance_name="$(echo "${resource_conformance}"|jq .name --raw-output)"
            echo "[INFO] Lease acquired! at $(date --utc) Leased resource: ${resource_conformance}"
            boskosctl --server-url http://boskos.ci --owner-name "${LEASE_OWNER}" heartbeat --resource "${resource_conformance}" &
            heartbeats_conformance_pid=$!
          fi

          ovirt_engine_template_name="$(extract_leases_info ovirt_engine_template_name ${lease_path})"
          if [ "${LEASE_TYPE}" == "conformance" ]; then
            worker_cpu="8"
            worker_mem="16384"
            master_cpu="8"
            master_mem="16384"
          else
            worker_cpu="4"
            worker_mem="9000"
            master_cpu="4"
            master_mem="9000"
            ovirt_engine_template_name="${ovirt_engine_template_name}-8G"
          fi

          #Saving parameters for the env
          cat > /tmp/shared/ovirt-lease.conf <<EOF
          OVIRT_APIVIP="$(extract_leases_info ovirt_apivip ${lease_path})"
          OVIRT_DNSVIP="$(extract_leases_info ovirt_dnsvip ${lease_path})"
          OVIRT_INGRESSVIP="$(extract_leases_info ovirt_ingressvip ${lease_path})"
          WORKER_CPU="${worker_cpu}"
          WORKER_MEM="${worker_mem}"
          MASTER_CPU="${master_cpu}"
          MASTER_MEM="${master_mem}"
          OCP_CLUSTER="$(extract_leases_info cluster_name ${lease_path})"
          OVIRT_ENGINE_CLUSTER_ID="$(extract_leases_info ovirt_engine_cluster_id ${lease_path})"
          OVIRT_ENGINE_TEMPLATE_NAME="${ovirt_engine_template_name}"
          EOF

          touch /tmp/shared/leased

          function release() {
              echo "killing heartbeat process "${heartbeats_pid}" at $(date --utc)"
              kill -9 "${heartbeats_pid}"
              echo "[INFO] Releasing the lease on resouce ${resource_name}"
              boskosctl --server-url http://boskos.ci --owner-name "${LEASE_OWNER}" release --name "${resource_name}" --target-state "free"
              if [ "${LEASE_TYPE}" == "conformance" ]; then
                echo "killing heartbeat process "${heartbeats_conformance_pid}" at $(date --utc)"
                kill -9 "${heartbeats_conformance_pid}"
                echo "[INFO] Releasing the lease on resouce ${resource_conformance}"
                boskosctl --server-url http://boskos.ci --owner-name "${LEASE_OWNER}" release --name "${resource_conformance_name}" --target-state "free"
              fi
          }

          trap "release" EXIT
          trap "release" TERM

          while true; do
            if [[ -f /tmp/shared/force-exit ]]; then
              echo "Another process exited" 2>&1
              exit 1
            fi
            if [[ -f /tmp/shared/teardown-exit ]]; then
              echo "Another process exited" 2>&1
              exit 0
            fi

            sleep 15 & wait $!
          done

      - name: setup
        image: quay.io/openshift/origin-ovirt-installer:latest
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - name: shared-tmp
          mountPath: /tmp/shared
        - name: cluster-profile
          mountPath: /etc/openshift-installer
        - name: installer-artifacts
          mountPath: /tmp/shared/artifacts
        env:
        - name: SSH_PUB_KEY_PATH
          value: /etc/openshift-installer/ssh-publickey
        - name: PULL_SECRET_PATH
          value: /etc/openshift-installer/pull-secret
        - name: OPENSHIFT_INSTALL_RELEASE_IMAGE_OVERRIDE
          value: PLACEHOLDER_OPENSHIFT_INSTALL_RELEASE_IMAGE_OVERRIDE
        - name: USE_LEASE
          value: PLACEHOLDER_USE_LEASE
        - name: USE_OVIRT_TEMPLATE
          value: PLACEHOLDER_USE_OVIRT_TEMPLATE
        - name: LEASE_TYPE
          value: PLACEHOLDER_LEASE_TYPE
        - name: STOP_AFTER_SETUP
          value: PLACEHOLDER_STOP_AFTER_SETUP
        command:
        - /bin/sh
        - -c
        - |
          #!/bin/sh
          trap 'rc=$?; if test "${rc}" -eq 0; then touch /tmp/shared/setup-pod.done; else touch /tmp/shared/force-exit; fi; exit "${rc}"' EXIT
          trap 'CHILDREN=$(jobs -p); if test -n "${CHILDREN}"; then kill ${CHILDREN} && wait; fi' TERM

          while true; do
            if [[ -f /tmp/shared/force-exit ]]; then
              echo "Another process exited" 2>&1
              exit 1
            fi
            if [[ -f /tmp/shared/leased ]]; then
              echo "Lease acquired, installing..."
              break
            fi
            sleep 15 & wait
          done

          function set_fake_lease_parameters() {
            template_name="rhcos-master-18"
            if [ "${LEASE_TYPE}" == "conformance" ]; then
              worker_cpu="8"
              worker_mem="16384"
              master_cpu="8"
              master_mem="16384"
            else
              worker_cpu="4"
              worker_mem="9000"
              master_cpu="4"
              master_mem="9000"
              template_name="${template_name}-8G"
            fi

            cat > /tmp/shared/ovirt-lease.conf <<EOF
            OVIRT_APIVIP="192.168.218.30"
            OVIRT_DNSVIP="192.168.218.31"
            OVIRT_INGRESSVIP="192.168.218.32"
            OCP_CLUSTER="ovirt18"
            OVIRT_ENGINE_CLUSTER_ID="8c93d26d-802b-4214-a9f5-58267dab3419"
            OVIRT_ENGINE_TEMPLATE_NAME="${template_name}"
            WORKER_CPU="${worker_cpu}"
            WORKER_MEM="${worker_mem}"
            MASTER_CPU="${master_cpu}"
            MASTER_MEM="${master_mem}"
          EOF
          }

          function create_ovirt_config() {
            # We want the setup to download the latest CA from the engine therefor living it empty
            export OVIRT_CONFIG=/tmp/shared/artifacts/installer/ovirt-config.yaml
            cat > /tmp/shared/artifacts/installer/ovirt-config.yaml <<EOF
            ovirt_url: ${OVIRT_ENGINE_URL}
            ovirt_username: ${OVIRT_ENGINE_USERNAME}
            ovirt_password: ${OVIRT_ENGINE_PASSWORD}
            ovirt_cafile: ""
            ovirt_insecure: true
          EOF
          }

          function export_vars() {
            export EXPIRATION_DATE=$(date -d '4 hours' --iso=minutes --utc)
            export SSH_PUB_KEY=$(cat "${SSH_PUB_KEY_PATH}")
            export PULL_SECRET=$(cat "${PULL_SECRET_PATH}")
            export TF_VAR_ovirt_template_mem=${WORKER_MEM}
            export TF_VAR_ovirt_template_cpu=${WORKER_CPU}
            export TF_VAR_ovirt_master_mem=${MASTER_MEM}
            export TF_VAR_ovirt_master_cpu=${MASTER_CPU}
          }

          function create_install_config() {
            cat > /tmp/shared/artifacts/installer/install-config.yaml <<EOF
            apiVersion: v1
            baseDomain: ${BASE_DOMAIN}
            metadata:
              name: ${OCP_CLUSTER}
            compute:
            - hyperthreading: Enabled
              name: worker
              platform:
                ovirt:
                  cpu:
                    cores: ${WORKER_CPU}
                    sockets: 1
                  memoryMB: ${WORKER_MEM}
                  osDisk:
                    # 31 is used to trigger the instance customization (the disk size is 16 Gi)
                    sizeGB: 31
                  vmType: server
                  instanceTypeID:
              replicas: 2
            controlPlane:
              hyperthreading: Enabled
              name: master
              platform:
                ovirt:
                  cpu:
                    cores: ${MASTER_CPU}
                    sockets: 1
                  memoryMB: ${MASTER_MEM}
                  osDisk:
                    # 31 is used to trigger the instance customization (the disk size is 16 Gi)
                    sizeGB: 31
                  vmType: server
                  instanceTypeID:
              replicas: 3
            platform:
              ovirt:
                ovirt_cluster_id: ${OVIRT_ENGINE_CLUSTER_ID}
                ovirt_storage_domain_id: ${OVIRT_ENGINE_STORAGE_DOMAIN_ID}
                api_vip: ${OVIRT_APIVIP}
                dns_vip: ${OVIRT_DNSVIP}
                ingress_vip: ${OVIRT_INGRESSVIP}
            pullSecret: >
              ${PULL_SECRET}
            sshKey: |
              ${SSH_PUB_KEY}
          EOF
          }

          function download_oc() {
            pushd /tmp/shared/artifacts
            echo "downloading oc binary"
            wget https://mirror.openshift.com/pub/openshift-v4/clients/oc/4.5/linux/oc.tar.gz -O oc.tar.gz
            tar xvfz oc.tar.gz
            chmod +x ./oc
            popd
          }

          function download_jq() {
            pushd /tmp/shared/artifacts
            wget https://github.com/stedolan/jq/releases/download/jq-1.5/jq-linux64 -O jq
            chmod +x ./jq
            popd
          }

          function update_image_registry() {
            while true; do
              sleep 10;
              oc get configs.imageregistry.operator.openshift.io/cluster >/dev/null 2>&1 && break
            done
            oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{"spec":{"managementState":"Managed","storage":{"emptyDir":{}}}}'
          }

          cp "$(command -v openshift-install)" /tmp/shared/

          mkdir -p /tmp/shared/artifacts/installer
          export PATH=$PATH:/tmp/shared:/tmp/shared/artifacts
          download_jq
          if [ "$USE_LEASE" == "false" ]; then
            set_fake_lease_parameters
          fi

          source /etc/openshift-installer/ovirt.conf
          source /tmp/shared/ovirt-lease.conf

          create_ovirt_config
          export_vars
          if [ "$USE_OVIRT_TEMPLATE" == "true" ]; then
            export OPENSHIFT_INSTALL_OS_IMAGE_OVERRIDE="${OVIRT_ENGINE_TEMPLATE_NAME}"
          fi

          create_install_config

          #download oc if missing
          if [ ! -f oc ] ; then
            download_oc
          fi

          cat /tmp/shared/artifacts/installer/install-config.yaml
          cp "$(command -v openshift-install)" /tmp/shared/
          #Done with configuration we can install now

          TF_LOG=debug openshift-install --dir=/tmp/shared/artifacts/installer create ignition-configs --log-level=debug
          echo "done with ignition-configs"

          python -c \
              'import json, sys; j = json.load(sys.stdin); j[u"systemd"][u"units"] = [{u"contents": "[Unit]\nDescription=Mount etcd as a ramdisk\nBefore=local-fs.target\n[Mount]\n What=none\nWhere=/var/lib/etcd\nType=tmpfs\nOptions=size=2G\n[Install]\nWantedBy=local-fs.target", u"enabled": True, u"name":u"var-lib-etcd.mount"}]; json.dump(j, sys.stdout)' \
              </tmp/shared/artifacts/installer/master.ign \
              >/tmp/shared/artifacts/installer/master.ign.out
          mv /tmp/shared/artifacts/installer/master.ign.out /tmp/shared/artifacts/installer/master.ign

          export KUBECONFIG=/tmp/shared/artifacts/installer/auth/kubeconfig
          update_image_registry &

          # What were doing here is we generate manifests first and force that OpenShift SDN is configured.
          TF_LOG=debug openshift-install --dir=/tmp/shared/artifacts/installer create manifests --log-level=debug

          sed -i '/^  channel:/d' /tmp/shared/artifacts/installer/manifests/cvo-overrides.yaml
          echo "done with manifests"

          TF_LOG=debug openshift-install --dir=/tmp/shared/artifacts/installer create cluster --log-level=debug

          install_exit_status=$?

          if [ "${STOP_AFTER_SETUP}" == "true" ]; then
            sleep 360m
          fi

          exit $install_exit_status

      - name: run-tests
        image: quay.io/openshift/origin-tests:latest
        imagePullPolicy: IfNotPresent
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - name: config-gcp-secrets
          mountPath: /runner/gcp-secrets
        - name: shared-tmp
          mountPath: /tmp/shared
        - name: cluster-profile
          mountPath: /etc/openshift-installer
        - name: installer-artifacts
          mountPath: /tmp/shared/artifacts
        env:
        - name: TEST
          value: PLACEHOLDER_TEST
        - name: STOP_AFTER_TEST
          value: PLACEHOLDER_STOP_AFTER_TEST
        - name: STOP_BEFORE_TEST
          value: PLACEHOLDER_STOP_BEFORE_TEST
        resources:
          requests:
            cpu: 4
            memory: 600Mi
          limits:
            memory: 4Gi
        command:
        - /bin/sh
        - -c
        - |
          #!/bin/bash
          trap 'rc=$?; teardown; touch /tmp/shared/teardown-exit; exit $rc' EXIT
          trap 'rc=$?; kill $(jobs -p); teardown; touch /tmp/shared/teardown-exit; exit $rc' TERM

          set -euo pipefail
          set -x

          function teardown() {
            export PATH=$PATH:/tmp/shared:/tmp/shared/artifacts
            export KUBECONFIG=/tmp/shared/artifacts/installer/auth/kubeconfig
            source /etc/openshift-installer/ovirt.conf
            source /tmp/shared/ovirt-lease.conf

            #We set OVIRT_CONFIG and insert he path to the engine ca to the config file
            export OVIRT_CONFIG=/tmp/shared/artifacts/installer/ovirt-config.yaml
            curl -k -o "/tmp/shared/artifacts/installer/ovirt-engine.ca" ${OVIRT_ENGINE_URL::-4}/services/pki-resource?resource=ca-certificate
            sed 's|ovirt_cafile: ""|ovirt_cafile: /tmp/shared/artifacts/installer/ovirt-engine.ca|' -i /tmp/shared/artifacts/installer/ovirt-config.yaml
            echo "Destroy bootstrap ..."
            openshift-install --dir /tmp/shared/artifacts/installer destroy bootstrap
            echo "Destroy cluster ..."
            openshift-install --dir /tmp/shared/artifacts/installer destroy cluster
            # Clean up
            rm -f /tmp/shared/artifacts/installer/ovirt-config.yaml
          }

          echo "waiting for installation to complete..."
          while true; do
            if [[ -f /tmp/shared/setup-pod.done ]]; then
              break
            fi
            if [[ -f /tmp/shared/force-exit ]]; then
              exit 1
            fi
            sleep 20 & wait
          done
          echo "beginning testing..."

          export PATH=$PATH:/tmp/shared:/tmp/shared/artifacts
          export KUBECONFIG=/tmp/shared/artifacts/installer/auth/kubeconfig
          source /etc/openshift-installer/ovirt.conf
          source /tmp/shared/ovirt-lease.conf

          cd /tmp/shared/artifacts
          mkdir -p junit/

          curl -k --connect-timeout 2 --retry 30 --retry-delay 30 https://api.${OCP_CLUSTER}.gcp.devcluster.openshift.com:6443/apis/config.openshift.io/v1/infrastructures/cluster
          sleep 360m
          if [ "${STOP_BEFORE_TEST}" == "true" ]; then
            sleep 360m
          fi

          if [ "${TEST}" == "conformance" ]; then
            openshift-tests run openshift/conformance/parallel \
              --provider '{"type":"ovirt"}' -o run_conformance.log -junit-dir junit/
          else
            # Grab all of the tests marked Feature:Builds and conformance/parallel/minimal
            openshift-tests run openshift/conformance/parallel --dry-run |
              grep 'Early' |
            openshift-tests run -o run_conformance.log --provider '{"type":"ovirt"}' \
              -junit-dir junit/ -f -
          fi

          if [ "${STOP_AFTER_TEST}" == "true" ]; then
            sleep 360m
          fi

          exit 0
      volumes:
        - name: config-gcp-secrets
          secret:
            secretName: ovirt-infra-gcp-secrets
        - name: cluster-profile
          projected:
            sources:
            - secret:
                name: cluster-secrets-ovirt
            - secret:
                name: ovirt-infra-secrets
        - name: shared-tmp
          emptyDir: {}
        - name: installer-artifacts
          emptyDir: {}
        - name: scripts
          configMap:
            name: ocp-on-rhv-ci-scripts
      restartPolicy: Never
